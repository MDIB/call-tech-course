{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 0 -> head 1 -> tail\n",
    "def toss_coin(times):\n",
    "    return np.random.choice(2,times)\n",
    "\n",
    "def toss_experiment(times):\n",
    "    return list(map(lambda x: [x,toss_coin(10)],range(times)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min freq : 0.00372\n",
      "first freq : 0.00372\n",
      "rand freq : 0.00372\n"
     ]
    }
   ],
   "source": [
    "total_freq_min = 0\n",
    "total_freq_rand = 0\n",
    "total_freq_first = 0\n",
    "for i in range(1000):\n",
    "    experiment = toss_experiment(1000)\n",
    "    first = experiment[0]\n",
    "    rand = experiment[np.random.choice(len(experiment)) - 1]\n",
    "\n",
    "    min_heads = max(experiment,key = lambda x: sum(x[1]))\n",
    "\n",
    "    total_freq_min += (10 - sum(min_heads[1]))/10\n",
    "    total_freq_first += (10 - sum(first[1]))/10\n",
    "    total_freq_rand += (10 - sum(rand[1]))/10\n",
    "\n",
    "print('min freq :',total_freq_min/10000)    \n",
    "print('first freq :',total_freq_min/10000)    \n",
    "print('rand freq :',total_freq_min/10000)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateLine():\n",
    "    x1,y1 = np.random.uniform(-1,1),np.random.uniform(-1,1)\n",
    "    \n",
    "    x2,y2 = np.random.uniform(-1,1),np.random.uniform(-1,1)\n",
    "    eq = np.array([[x1,1],[x2,1]])\n",
    "    res = np.array([y1,y2])\n",
    "    return np.linalg.solve(eq,res)\n",
    "\n",
    "def classify(slope,intercept,x,y):\n",
    "    w = (y - intercept)/float(slope)\n",
    "    if(x > w):\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14\n",
      "0.07\n"
     ]
    }
   ],
   "source": [
    "import numpy.linalg as linalg\n",
    "from functools import partial\n",
    "\n",
    "in_freq=[]\n",
    "out_freq=[]\n",
    "\n",
    "SAMPLE_SIZE = 100\n",
    "EXPERIMENT_TIMES = 1\n",
    "OUT_OF_SAMPLE_SIZE = 1000\n",
    "\n",
    "slope,intercept = generateLine()\n",
    "f = partial(classify,slope,intercept) \n",
    "  \n",
    "def train_linear(features,labels):\n",
    "    return linalg.pinv(features).dot(labels)\n",
    "\n",
    "def predict(user_features,optimal_weights):\n",
    "    return np.sign(np.array(user_features).dot(optimal_weights))\n",
    "        \n",
    "        \n",
    "for i in range(EXPERIMENT_TIMES): \n",
    "    features = [[np.random.uniform(-1,1),np.random.uniform(1,-1)] for i in range(SAMPLE_SIZE)]\n",
    "    out_of_sample = [[np.random.uniform(-1,1),np.random.uniform(1,-1)] for i in range(OUT_OF_SAMPLE_SIZE)]\n",
    "    \n",
    "    labels = list(map(lambda x: f(x[0],x[1]),features))\n",
    "    out_of_sample_labels = list(map(lambda x: f(x[0],x[1]),out_of_sample))\n",
    "  \n",
    "    optimal_weights = np.array(train_linear(np.matrix(features),labels))[0]\n",
    "    \n",
    "    in_error = 0\n",
    "    for i in range(len(features)):\n",
    "        user_weights = features[i]\n",
    "        expected = labels[i]\n",
    "        actual = predict(user_weights,optimal_weights)\n",
    "        if(actual != expected):   \n",
    "            in_error += 1\n",
    "    in_freq.append(in_error/float(SAMPLE_SIZE))\n",
    "    \n",
    "    out_error=0\n",
    "    for i in range(len(out_of_sample_labels)):\n",
    "        user_weights = out_of_sample[i]\n",
    "        expected = out_of_sample_labels[i]\n",
    "        actual = predict(user_weights,optimal_weights)\n",
    "        if(actual != expected):   \n",
    "            out_error += 1\n",
    "            \n",
    "    out_freq.append(out_error/float(OUT_OF_SAMPLE_SIZE))\n",
    "\n",
    "print(np.average(in_freq)) #answer to the 5th -> c\n",
    "\n",
    "print(np.average(out_freq)) #answer to the 6th -> c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.56419445  0.72173249]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_SIZE = 10\n",
    "EXPERIMENT_SIZE = 1000\n",
    "features = [[np.random.uniform(-1,1),np.random.uniform(1,-1)] for i in range(SAMPLE_SIZE)]\n",
    "labels = list(map(lambda x: f(x[0],x[1]),features))\n",
    "\n",
    "weights = train_linear(features,labels)\n",
    "print(weights)\n",
    "\n",
    "def train_PLA(weights,features,labels,learning_rate):\n",
    "    iterations = 0\n",
    "    minimum_error = -1\n",
    "    best_weights = []\n",
    "    error_sum = 1\n",
    "    while(error_sum != 0):\n",
    "        error_sum = 0\n",
    "        iterations += 1\n",
    "        for i in range(len(features)):\n",
    "            row = features[i]\n",
    "            expected = labels[i]\n",
    "            actual = predict(row,weights)\n",
    "            if actual != expected:\n",
    "                error_sum += 1\n",
    "                for w in range(len(weights) -1):\n",
    "                    weights[w + 1] = weights[w + 1] + learning_rate * row[w + 1]\n",
    "    \n",
    "        if(minimum_error == -1 or error_sum < minimum_error):\n",
    "            minimum_error = error_sum\n",
    "            best_weights = list(weights) \n",
    "                \n",
    "    return best_weights,iterations\n",
    "\n",
    "iterations_vec = []\n",
    "\n",
    "for i in range(EXPERIMENT_SIZE):    \n",
    "    weights,iterations = train_PLA(weights,features,labels,0.1)\n",
    "    iterations_vec.append(iterations)\n",
    "\n",
    "print(np.average(iterations_vec)) #answer to 7th --> a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.482809\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_SIZE = 1000\n",
    "EXPERIMENT_SIZE = 1000\n",
    "\n",
    "in_freq =  []\n",
    "\n",
    "def non_linear_target(x1,x2):\n",
    "    return np.sign((x1**2)+(x2**2)-0.6)\n",
    "    \n",
    "for j in range(EXPERIMENT_SIZE):\n",
    "    features = [[np.random.uniform(-1,1),np.random.uniform(1,-1)] for i in range(SAMPLE_SIZE)]\n",
    "    \n",
    "    features_and_labels = list(map(lambda x: (x,non_linear_target(x[0],x[1])),features))\n",
    "    \n",
    "    np.random.shuffle(features_and_labels)\n",
    "    \n",
    "    for i in (range(int(SAMPLE_SIZE/10))):\n",
    "        features_and_labels[i] = (features_and_labels[i][0],-1*features_and_labels[i][1])\n",
    "    \n",
    "    random_noise_features = list(map(lambda x: x[0],features_and_labels))\n",
    "    random_noise_labels = list(map(lambda x: x[1],features_and_labels))\n",
    "    \n",
    "    optimal_weights = np.array(train_linear(np.matrix(random_noise_features),random_noise_labels))[0]\n",
    "    \n",
    "    in_error = 0\n",
    "    for i in range(SAMPLE_SIZE):\n",
    "        user_weights = random_noise_features[i]\n",
    "        expected = random_noise_labels[i]\n",
    "        actual = predict(user_weights,optimal_weights)\n",
    "        \n",
    "        if(actual != expected):   \n",
    "            in_error += 1\n",
    "    in_freq.append(in_error/float(SAMPLE_SIZE))\n",
    "\n",
    "print(np.average(in_freq))   # answer to 8th , WRONG, get avg of 0.17, correct answer is 0.5 \n",
    "                             # I've fix it !!! LOL LOL (I forgot to use the nonlinear target function...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12386\n",
      "x1: -0.000318529445794\n",
      "x2: -0.000450648393481\n",
      "x1*x2: -0.000101106847093\n",
      "x1**2: 1.56273727711\n",
      "x2**2: 1.56082115004\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_SIZE = 1000\n",
    "EXPERIMENT_SIZE = 1000\n",
    "\n",
    "in_freq =  []\n",
    "\n",
    "def non_linear_target(x1,x2):\n",
    "    return np.sign((x1**2)+(x2**2)-0.6)\n",
    "\n",
    "def non_linear_transformation(x1,x2):\n",
    "    return [1,x1,x2,x1*x2,x1**2,x2**2]\n",
    "\n",
    "def transform_features(features):\n",
    "    res = []\n",
    "    for i in range(len(features)):\n",
    "        res.append(non_linear_transformation(features[i][0],features[i][1]))\n",
    "    return res\n",
    "\n",
    "crazy_weights = []\n",
    "for j in range(EXPERIMENT_SIZE):\n",
    "    features = [[np.random.uniform(-1,1),np.random.uniform(1,-1)] for i in range(SAMPLE_SIZE)]\n",
    "    \n",
    "    features_and_labels = list(map(lambda x: (x,non_linear_target(x[0],x[1])),features))\n",
    "    \n",
    "    np.random.shuffle(features_and_labels)\n",
    "    \n",
    "    for i in (range(int(SAMPLE_SIZE/10))):\n",
    "        features_and_labels[i] = (features_and_labels[i][0],-1*features_and_labels[i][1])\n",
    "    \n",
    "    random_noise_features = transform_features(list(map(lambda x: x[0],features_and_labels)))\n",
    "    random_noise_labels = list(map(lambda x: x[1],features_and_labels))\n",
    "    \n",
    "    optimal_weights = np.array(train_linear(np.matrix(random_noise_features),random_noise_labels))[0]\n",
    "    crazy_weights.append(optimal_weights)\n",
    "\n",
    "    in_error = 0\n",
    "    for i in range(SAMPLE_SIZE):\n",
    "        user_features = transform_features([random_noise_features[i]])[0]\n",
    "        expected = random_noise_labels[i]\n",
    "        actual = predict(random_noise_features[i],optimal_weights)\n",
    "        \n",
    "        if(actual != expected):  \n",
    "            in_error += 1\n",
    "    in_freq.append(in_error/float(SAMPLE_SIZE))\n",
    "\n",
    "print(np.average(in_freq))  #answer to 10th exercise blaaah\n",
    "\n",
    "#So... I am not sure WTF but, in order to get a good prediction result I CANT \n",
    "#transform the user_weights with the transfome_features???? why?? \n",
    "#I thought that when we use nonlinear transformation we had to transform the user_features with the same fn we\n",
    "#picked to train our data... HELP\n",
    "\n",
    "def crazy_fn(n):\n",
    "    return np.average(list(map(lambda x : x[n],crazy_weights)))\n",
    "\n",
    "print(\"x1:\",crazy_fn(1))    \n",
    "print(\"x2:\",crazy_fn(2))    \n",
    "print(\"x1*x2:\",crazy_fn(3))    \n",
    "print(\"x1**2:\",crazy_fn(4))    \n",
    "print(\"x2**2:\",crazy_fn(5))    #all this results combine gave me the answer A in the 9th question, and it's correct...\n",
    "#NOT BAD :not_bad:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
